{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import math\n",
    "import ast\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from transformers import BertConfig, BertForSequenceClassification, BertTokenizer, BertTokenizerFast, BertModel, AdamW, TFBertModel\n",
    "from transformers.modeling_bert import BertEmbeddings, BertSelfAttention\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "PRE_TRAINED = 'bert-base-uncased'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ASPECT_NAMES = ['LEG', 'SIT', 'ENT', 'CUS', 'VOM', 'CLE', 'CKI', 'FNB']\n",
    "VOCAB_DIC = BertTokenizerFast.from_pretrained(PRE_TRAINED).get_vocab()\n",
    "TOPN = 50\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y=None):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(PRE_TRAINED)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        sen = self.x[i]\n",
    "        encoded = self.tokenizer.encode(sen)\n",
    "        encoded = pad_sequences([encoded], maxlen=512, padding='post')\n",
    "        if self.y is None:\n",
    "            return torch.FloatTensor(encoded[0])\n",
    "        else:\n",
    "            return torch.LongTensor(encoded[0]), torch.FloatTensor([self.y[i]])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.size\n",
    "    \n",
    "\n",
    "class BertBonz(BertModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertBonz, self).__init__(config)\n",
    "        self.config = config\n",
    "        self.embeddings.llr_embeddings = nn.ModuleList(nn.Embedding(4, 768, 3) for _ in range(len(ASPECT_NAMES)))\n",
    "        self.classifier = nn.Linear(768, config.num_aspect*3)\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "    def forward(self, \n",
    "                input_ids=None, \n",
    "                llr_ids=None, \n",
    "                labels=None, \n",
    "                token_type_ids=None, \n",
    "                position_ids=None):\n",
    "        # BERT EMBEDDINGS NEW\n",
    "        input_shape = input_ids.size()\n",
    "        seq_length = input_shape[1]\n",
    "        device = input_ids.device\n",
    "        \n",
    "        if position_ids is None:\n",
    "            position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "            position_ids = position_ids.unsqueeze(0).expand(input_shape)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "        inputs_embeds = self.embeddings.word_embeddings(input_ids)\n",
    "        position_embeddings = self.embeddings.position_embeddings(position_ids)\n",
    "        token_type_embeddings = self.embeddings.token_type_embeddings(token_type_ids)\n",
    "        \n",
    "        if llr_ids is not None:\n",
    "            temp = [self.embeddings.llr_embeddings[i](llr_ids[:,i,:]) for i in range(self.config.num_aspect)]\n",
    "            llr_embeddings = sum(temp)\n",
    "        else:\n",
    "            llr_embeddings = torch.zeros(inputs_embeds.size(), device=device)\n",
    "        \n",
    "        embeddings = inputs_embeds + position_embeddings + token_type_embeddings + llr_embeddings\n",
    "        embeddings = self.embeddings.LayerNorm(embeddings)\n",
    "        embeddings = self.embeddings.dropout(embeddings)\n",
    "        \n",
    "        \n",
    "        # BERT ENCODER\n",
    "        encoder_outputs = self.encoder(\n",
    "            embeddings,\n",
    "            attention_mask=None,\n",
    "            head_mask=[None]*12,\n",
    "            encoder_hidden_states=None,\n",
    "            encoder_attention_mask=None,\n",
    "            output_attentions=self.config.output_attentions\n",
    "        )\n",
    "        sequence_output = encoder_outputs[0]\n",
    "        \n",
    "        # CLASSIFIER\n",
    "        CLS_token = sequence_output[:,0]\n",
    "        predict = self.classifier(CLS_token)\n",
    "        \n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        if labels is not None:\n",
    "            loss = loss_fn(predict.view(input_shape[0], 3,-1), labels)\n",
    "            outputs = (predict.view(input_shape[0], 3,-1), loss, CLS_token, sequence_output) + encoder_outputs[1:]  # add hidden_states and attentions if they are here\n",
    "        else:\n",
    "            outputs = (predict.view(input_shape[0], 3,-1), CLS_token, sequence_output) + encoder_outputs[1:]\n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "    def load_pretrained_weight(self):\n",
    "        sd = self.state_dict()\n",
    "        sd_bert_pretrained = BertModel.from_pretrained(PRE_TRAINED).state_dict()\n",
    "        for k in sd_bert_pretrained.keys():\n",
    "            if k in sd.keys():\n",
    "                sd[k] = sd_bert_pretrained[k]\n",
    "        self.load_state_dict(sd)\n",
    "        print('Succesfully load pre-trained weights')\n",
    "        \n",
    "    def llr_embed_pad(self):\n",
    "        for i in range(len(ASPECT_NAMES)):\n",
    "            temp = self.embeddings.llr_embeddings[i].weight.data\n",
    "            temp[-1,:] = torch.zeros(temp.size(1))\n",
    "        \n",
    "        \n",
    "    def fit(self, \n",
    "            optimizer=None, \n",
    "            lr=2e-5,\n",
    "            loss=None):\n",
    "        self.optimizer = optimizer(self.parameters(), lr)\n",
    "        self.loss_fn = loss\n",
    "        \n",
    "        \n",
    "    def train_(self, \n",
    "              inputs=None, \n",
    "              labels=None, \n",
    "              epochs=None, \n",
    "              batch_size=None):\n",
    "        self.to(DEVICE)\n",
    "        self.train()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            my_dataset = MyDataset(inputs, labels)\n",
    "            dataloader = DataLoader(my_dataset, batch_size=batch_size, shuffle=True)\n",
    "            s = time.time()\n",
    "            loss_train = 0\n",
    "            for x, y in dataloader:\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self(input_ids=x.to(DEVICE), labels=y.to(DEVICE))\n",
    "                loss = outputs[1]\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                loss_train += loss.item()\n",
    "                \n",
    "                predict = outputs[0]\n",
    "                print(predict.detach().cpu().numpy().squeeze(-1).tolist())\n",
    "            print(f'Finish epoch {epoch+1}, loss = {loss_train:.2f}, running time {time.time()-s:.2f}')\n",
    "\n",
    "    \n",
    "    \n",
    "def train(model=None, epochs=None):\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "    model.train()\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        my_dataset = MyDataset(x=data['Review\\'s Content'].values, y=data.sentiment.values)\n",
    "        dataloader = DataLoader(my_dataset, batch_size=4, shuffle=True)\n",
    "        s = time.time()\n",
    "        for x, y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(x=x.to(DEVICE), y=y.to(DEVICE))[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('Finish epoch {}, running time {}'.format(epoch+1, time.time()-s))\n",
    "            \n",
    "    model.eval()\n",
    "    predicts=[]\n",
    "    y_true=[]\n",
    "    for x, y in dataloader:\n",
    "        with torch.no_grad():\n",
    "            predict = model(x=x.to(DEVICE))\n",
    "        predict = predict.detach().cpu().numpy()\n",
    "        predict = predict > 0.5\n",
    "        predicts.extend(predict.tolist())\n",
    "        y_true.extend(y.numpy().tolist())\n",
    "        \n",
    "    print(classification_report(y_true, predicts))\n",
    "    return model\n",
    "\n",
    "\n",
    "def split_aspect(data):\n",
    "    temp = np.full((8, data.shape[0]), 2, np.int)\n",
    "    for idx in range(data.shape[0]):\n",
    "        aspect = data[idx]\n",
    "        for i, asp in enumerate(['Legroom', 'Seat', 'Entertainment', 'Customer', 'Value', 'Cleanliness', 'Check-in', 'Food']):\n",
    "            for sub_asp in aspect:\n",
    "                if asp in sub_asp:\n",
    "                    pol = int(sub_asp[-1])\n",
    "                    temp[i, idx] = 1 if pol > 3 else 0\n",
    "                    break\n",
    "    return temp\n",
    "            \n",
    "\n",
    "def tokenize_data(data):\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(PRE_TRAINED)\n",
    "    input_ids = tokenizer(list(data))['input_ids']\n",
    "    input_ids = pad_sequences(input_ids, maxlen=512, padding='post', truncating='post')\n",
    "    \n",
    "    return list(input_ids)\n",
    "    \n",
    "    \n",
    "def get_data():\n",
    "    col_names = ['TopNumber', 'AirlineName','ReviewerName','Rating','ReviewDate','ReviewTitle',\\\n",
    "                 'ReviewText','Tags', 'DateofTravel', 'Aspects', 'ResponserName', 'ResponseDate', 'ResponseText', 'ReviewerProfileUrl',\\\n",
    "                 'AirlineUrl','CrawlTime']\n",
    "    raw_data = pd.read_csv('./data/airline.txt', sep='\\t', header=None, names=col_names)\n",
    "    data = raw_data[['ReviewText', 'Rating', 'Aspects']]\n",
    "    data = data[data['Aspects'] != 'No filling in'].reset_index(drop=True) # Filter none aspects\n",
    "    data.Aspects = data.Aspects.str.split('|').values\n",
    "    \n",
    "    '''Split aspects to new columns'''\n",
    "    aspects_splitted = split_aspect(data.Aspects.values)\n",
    "    for i in range(len(ASPECT_NAMES)):\n",
    "        data[ASPECT_NAMES[i]] = aspects_splitted[i,:]\n",
    "        \n",
    "    data['input_ids'] = tokenize_data(data.ReviewText.values) # Generate input_ids from review text\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def word_class_freq(data, aspect_name, aspect_class=3):\n",
    "    temp = np.zeros((33000, aspect_class), np.int)\n",
    "    ids = data.input_ids.values\n",
    "    labels = data[aspect_name].values\n",
    "\n",
    "    for sub_ids, sub_lb in zip(ids, labels):\n",
    "        set_ids = set(sub_ids)\n",
    "        for ids in set_ids:\n",
    "            temp[ids, sub_lb] += 1\n",
    "    \n",
    "    return temp\n",
    "\n",
    "\n",
    "def calculate_llr(temp_df, labels):\n",
    "    N = data.shape[0]\n",
    "    total_scores = []\n",
    "\n",
    "    for i in temp_df.index.values:\n",
    "        llr_scores = []\n",
    "        for class_ in [0,1,2]:\n",
    "            num_class_doc = np.sum(labels == class_)\n",
    "            n11 = temp_df.loc[i, class_]\n",
    "            n10 = num_class_doc - n11\n",
    "            n01 = temp_df.loc[i, 'total'] - n11\n",
    "            n00 = (N - n11 - n10 - n01)\n",
    "            pt = (1e-10 + n11 + n01)/N\n",
    "            p1 = n11/(1e-10 + n11 + n10)\n",
    "            p2 = n01/(1e-10 + n01 + n00)\n",
    "\n",
    "\n",
    "            try:\n",
    "                e1 = n11 * (math.log(pt) - math.log(p1))\n",
    "            except:\n",
    "                e1 = 0\n",
    "            try:\n",
    "                e2 = n10 * (math.log(1-pt) - math.log(1-p1))\n",
    "            except:\n",
    "                e2 = 0\n",
    "            try:\n",
    "                e3 = n01 * (math.log(pt) - math.log(p2))\n",
    "            except:\n",
    "                e3 = 0\n",
    "            try:\n",
    "                e4 = n00 * (math.log(1-pt) - math.log(1-p2))\n",
    "            except:\n",
    "                e4 = 0\n",
    "\n",
    "            llr_score = -2 * (e1+e2+e3+e4)\n",
    "            if n11 < n01:\n",
    "                llr_score = 0\n",
    "            llr_scores.append(llr_score)\n",
    "\n",
    "        total_scores.append(llr_scores)\n",
    "    \n",
    "    llr_df = pd.DataFrame(np.array(total_scores), index=temp_df.index, columns=temp_df.columns.values[:-1])\n",
    "\n",
    "    return llr_df\n",
    "\n",
    "\n",
    "def generate_llr_score(data, aspect):\n",
    "    temp = word_class_freq(data, aspect)\n",
    "    \n",
    "    temp_df = pd.DataFrame(temp)\n",
    "    temp_df['total'] = np.sum(temp, -1)\n",
    "    temp_df = temp_df[temp_df['total'] != 0]\n",
    "    temp_df = temp_df.drop(0,0)\n",
    "    \n",
    "    return calculate_llr(temp_df, data[aspect].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb3e14aa1324c8da1c4b436b8eaffc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8713a26f20e54cb6901829ca10dd4f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=141116.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9094acea9cb140afb2d7b65e15fac136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=141116.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342fbe73e0d04a35868e4319a259d143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=141116.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('new_data.csv', sep='\\t', index_col=0)\n",
    "\n",
    "for col in tqdm.notebook.tqdm(['input_ids', 'labels', 'llr_embeddings']):\n",
    "    data[col] = [ast.literal_eval(i) for i in tqdm.notebook.tqdm(data[col].values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data()\n",
    "data['labels'] = list(data.iloc[:, 3:11].values)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCULATE LLR SCORES & WORDLIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09530a827b3d4b1a9a90e46512df61a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Calculate LLR scores', max=8.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llr_scores = {}\n",
    "for aspect in tqdm.notebook.tqdm(ASPECT_NAMES, desc='Calculate LLR scores'):\n",
    "    llr_df = generate_llr_score(data, aspect)\n",
    "    llr_scores[aspect] = llr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c45c02e9bfa4fb0a74618bd113f92f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generate top LLR words', max=8.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llr_words = dict()\n",
    "\n",
    "for aspect in tqdm.notebook.tqdm(ASPECT_NAMES, desc='Generate top LLR words'):\n",
    "    kw_label = dict()\n",
    "    for class_ in [0,1,2]:\n",
    "        kw_list = list(llr_scores[aspect][class_].sort_values(ascending=False)[:TOPN].index)\n",
    "        kw_label[class_] = kw_list\n",
    "    llr_words[aspect] = kw_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0395d5977b4c8295a43cd986587441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=141116.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Aspects</th>\n",
       "      <th>LEG</th>\n",
       "      <th>SIT</th>\n",
       "      <th>ENT</th>\n",
       "      <th>CUS</th>\n",
       "      <th>VOM</th>\n",
       "      <th>CLE</th>\n",
       "      <th>CKI</th>\n",
       "      <th>FNB</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "      <th>llr_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So, I had this trip aligned for family leisure...</td>\n",
       "      <td>5</td>\n",
       "      <td>[Legroom:4, Seat comfort:5, In-flight Entertai...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2061, 1010, 1045, 2018, 2023, 4440, 1311...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[[3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Refund agreed to months ago but basically been...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Legroom:1, Seat comfort:1, In-flight Entertai...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 25416, 8630, 3530, 2000, 2706, 3283, 202...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[[3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 0, 3, 3, 1, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flying to London on Singapore Airlines, we had...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Legroom:3, Seat comfort:4, In-flight Entertai...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 3909, 2000, 2414, 2006, 5264, 7608, 1010...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[[3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I thought we were making a safe choice booking...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Customer service:1]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[101, 1045, 2245, 2057, 2020, 2437, 1037, 3647...</td>\n",
       "      <td>[2, 2, 2, 0, 2, 2, 2, 2]</td>\n",
       "      <td>[[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wonderful service on our trip out to New Zeala...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Legroom:5, Seat comfort:4, In-flight Entertai...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 6919, 2326, 2006, 2256, 4440, 2041, 2000...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[[3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141111</th>\n",
       "      <td>ANA is partnered with Air Canada for their fli...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Legroom:4, Seat comfort:4, In-flight Entertai...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[101, 9617, 2003, 12404, 2007, 2250, 2710, 200...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 2, 2, 2]</td>\n",
       "      <td>[[3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141112</th>\n",
       "      <td>This is my first time flying with ANA. Overall...</td>\n",
       "      <td>5</td>\n",
       "      <td>[Legroom:4, Seat comfort:4, In-flight Entertai...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[101, 2023, 2003, 2026, 2034, 2051, 3909, 2007...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 2, 2, 2]</td>\n",
       "      <td>[[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141113</th>\n",
       "      <td>Excellent Airline to fly with, nice staff and ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Legroom:5, Seat comfort:5, In-flight Entertai...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[101, 6581, 8582, 2000, 4875, 2007, 1010, 3835...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 2, 2]</td>\n",
       "      <td>[[3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141114</th>\n",
       "      <td>We traveled on ANA with our 1 year old baby. I...</td>\n",
       "      <td>5</td>\n",
       "      <td>[Legroom:5, Seat comfort:4, In-flight Entertai...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[101, 2057, 6158, 2006, 9617, 2007, 2256, 1015...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 2, 2]</td>\n",
       "      <td>[[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141115</th>\n",
       "      <td>Nice flight from Manila to Japan, the only dow...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Legroom:3, Seat comfort:4, In-flight Entertai...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[101, 3835, 3462, 2013, 9011, 2000, 2900, 1010...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 2, 2, 2]</td>\n",
       "      <td>[[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141116 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ReviewText  Rating  \\\n",
       "0       So, I had this trip aligned for family leisure...       5   \n",
       "1       Refund agreed to months ago but basically been...       1   \n",
       "2       Flying to London on Singapore Airlines, we had...       4   \n",
       "3       I thought we were making a safe choice booking...       1   \n",
       "4       Wonderful service on our trip out to New Zeala...       4   \n",
       "...                                                   ...     ...   \n",
       "141111  ANA is partnered with Air Canada for their fli...       4   \n",
       "141112  This is my first time flying with ANA. Overall...       5   \n",
       "141113  Excellent Airline to fly with, nice staff and ...       4   \n",
       "141114  We traveled on ANA with our 1 year old baby. I...       5   \n",
       "141115  Nice flight from Manila to Japan, the only dow...       4   \n",
       "\n",
       "                                                  Aspects  LEG  SIT  ENT  CUS  \\\n",
       "0       [Legroom:4, Seat comfort:5, In-flight Entertai...    1    1    1    1   \n",
       "1       [Legroom:1, Seat comfort:1, In-flight Entertai...    0    0    0    0   \n",
       "2       [Legroom:3, Seat comfort:4, In-flight Entertai...    0    1    1    1   \n",
       "3                                    [Customer service:1]    2    2    2    0   \n",
       "4       [Legroom:5, Seat comfort:4, In-flight Entertai...    1    1    1    1   \n",
       "...                                                   ...  ...  ...  ...  ...   \n",
       "141111  [Legroom:4, Seat comfort:4, In-flight Entertai...    1    1    0    1   \n",
       "141112  [Legroom:4, Seat comfort:4, In-flight Entertai...    1    1    1    1   \n",
       "141113  [Legroom:5, Seat comfort:5, In-flight Entertai...    1    1    1    1   \n",
       "141114  [Legroom:5, Seat comfort:4, In-flight Entertai...    1    1    1    1   \n",
       "141115  [Legroom:3, Seat comfort:4, In-flight Entertai...    0    1    1    1   \n",
       "\n",
       "        VOM  CLE  CKI  FNB                                          input_ids  \\\n",
       "0         1    1    1    1  [101, 2061, 1010, 1045, 2018, 2023, 4440, 1311...   \n",
       "1         0    0    0    0  [101, 25416, 8630, 3530, 2000, 2706, 3283, 202...   \n",
       "2         1    1    1    1  [101, 3909, 2000, 2414, 2006, 5264, 7608, 1010...   \n",
       "3         2    2    2    2  [101, 1045, 2245, 2057, 2020, 2437, 1037, 3647...   \n",
       "4         1    1    1    1  [101, 6919, 2326, 2006, 2256, 4440, 2041, 2000...   \n",
       "...     ...  ...  ...  ...                                                ...   \n",
       "141111    1    2    2    2  [101, 9617, 2003, 12404, 2007, 2250, 2710, 200...   \n",
       "141112    0    2    2    2  [101, 2023, 2003, 2026, 2034, 2051, 3909, 2007...   \n",
       "141113    1    2    2    2  [101, 6581, 8582, 2000, 4875, 2007, 1010, 3835...   \n",
       "141114    1    2    2    2  [101, 2057, 6158, 2006, 9617, 2007, 2256, 1015...   \n",
       "141115    1    2    2    2  [101, 3835, 3462, 2013, 9011, 2000, 2900, 1010...   \n",
       "\n",
       "                          labels  \\\n",
       "0       [1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2       [0, 1, 1, 1, 1, 1, 1, 1]   \n",
       "3       [2, 2, 2, 0, 2, 2, 2, 2]   \n",
       "4       [1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "...                          ...   \n",
       "141111  [1, 1, 0, 1, 1, 2, 2, 2]   \n",
       "141112  [1, 1, 1, 1, 0, 2, 2, 2]   \n",
       "141113  [1, 1, 1, 1, 1, 2, 2, 2]   \n",
       "141114  [1, 1, 1, 1, 1, 2, 2, 2]   \n",
       "141115  [0, 1, 1, 1, 1, 2, 2, 2]   \n",
       "\n",
       "                                           llr_embeddings  \n",
       "0       [[3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3,...  \n",
       "1       [[3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 0, 3, 3, 1, 3,...  \n",
       "2       [[3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3,...  \n",
       "3       [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...  \n",
       "4       [[3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...  \n",
       "...                                                   ...  \n",
       "141111  [[3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3,...  \n",
       "141112  [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3,...  \n",
       "141113  [[3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...  \n",
       "141114  [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...  \n",
       "141115  [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...  \n",
       "\n",
       "[141116 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llr_embedding_list = []\n",
    "\n",
    "for idx in tqdm.notebook.trange(data.shape[0]):\n",
    "    tokens = data.input_ids[idx]\n",
    "    \n",
    "    llr_embedding = []\n",
    "    for aspect in ASPECT_NAMES:\n",
    "        temp = [3] * tokens.shape[0]\n",
    "        for j in range(tokens.shape[0]):\n",
    "            for class_, wordlist in llr_words[aspect].items():\n",
    "                if tokens[j] in wordlist:\n",
    "                    temp[j] = class_\n",
    "                    break\n",
    "        llr_embedding.append(temp)\n",
    "    \n",
    "    llr_embedding_list.append(llr_embedding)\n",
    "\n",
    "#data['llr_embeddings'] = [[[0]*512]*8] * data.shape[0]\n",
    "data['llr_embeddings'] = llr_embedding_list\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE DATASET & DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BonzDataset(Dataset):\n",
    "    def __init__(self, data, llr_words):\n",
    "        self.input_ids = torch.LongTensor(list(data.input_ids))\n",
    "        self.llr_embeddings = torch.LongTensor(list(data.llr_embeddings))\n",
    "        if 'labels' in data.columns:\n",
    "            self.labels = torch.LongTensor(list(data.labels))\n",
    "        else:\n",
    "            self.labels = None\n",
    "        self.llr_words = llr_words\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.input_ids.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        tokens = self.data.input_ids[idx]\n",
    "        \n",
    "        llr_embedding = []\n",
    "        for aspect in ASPECT_NAMES:\n",
    "            temp = [3] * tokens.shape[0]\n",
    "            for j in range(tokens.shape[0]):\n",
    "                for class_, wordlist in llr_words[aspect].items():\n",
    "                    if tokens[j] in wordlist:\n",
    "                        temp[j] = class_\n",
    "                        break\n",
    "            llr_embedding.append(temp)\n",
    "        \n",
    "        llr_embedding = torch.stack([torch.LongTensor(i) for i in llr_embedding], 0)\n",
    "        \n",
    "        \n",
    "        outputs = (torch.LongTensor(tokens), llr_embedding)\n",
    "        \n",
    "        if 'labels' in self.data.columns:\n",
    "            outputs = (torch.LongTensor(tokens), llr_embedding, torch.LongTensor(self.data.labels[idx]))\n",
    "        '''\n",
    "        if self.labels is None:\n",
    "            outputs = (self.input_ids[idx], self.llr_embeddings[idx])\n",
    "        else:\n",
    "            outputs = (self.input_ids[idx], self.llr_embeddings[idx], self.labels[idx])\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "\n",
    "dataset = BonzDataset(data.iloc[:,-3:], None)\n",
    "dataloader = DataLoader(dataset, batch_size=7, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully load pre-trained weights\n"
     ]
    }
   ],
   "source": [
    "#del model\n",
    "config = BertConfig.from_pretrained('bert-base-uncased')\n",
    "config.num_aspect = len(ASPECT_NAMES)\n",
    "model = BertBonz(config)\n",
    "model.to(DEVICE)\n",
    "\n",
    "model.load_pretrained_weight() # Load pre-trained BERT weights for BERT's layers \n",
    "model.llr_embed_pad() # Set LLR embedding padding idx to 0-value tensor\n",
    "\n",
    "origin_sd = model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with K-FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb13272cae141e384107e46f30b4897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load origin state dict succesfully!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ed40493b034642b1c1142de3deefb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training with K-fold\n",
    "\n",
    "new_data = data.sample(frac=1).reset_index(drop=True)\n",
    "kf = KFold(10)\n",
    "\n",
    "last_predict = []\n",
    "for train_idx, test_idx in tqdm.notebook.tqdm(kf.split(new_data)):\n",
    "    train_data = new_data.iloc[train_idx]\n",
    "    test_data = new_data.iloc[test_idx]\n",
    "    model.load_state_dict(origin_sd)\n",
    "    print('Load origin state dict succesfully!!!')\n",
    "    \n",
    "    \"\"\" TRAINING \"\"\"\n",
    "    model.train()\n",
    "    dataset = BonzDataset(train_data.iloc[:,-3:], None)\n",
    "    dataloader = DataLoader(dataset, batch_size=7, shuffle=True)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    for epoch in tqdm.notebook.trange(5):\n",
    "        loss_train = 0\n",
    "        for idx, (a, b, c) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            #a, b, c = a.to(DEVICE), b.to(DEVICE), c.to(DEVICE)\n",
    "            predict, loss = model(a.to(DEVICE), b.to(DEVICE), c.to(DEVICE))[:2]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        print(f'Epoch: {epoch}, Loss = {loss_train:.2f}')\n",
    "        \n",
    "    \"\"\" TESTING \"\"\"\n",
    "    model.eval()\n",
    "    dataset = BonzDataset(test_data.iloc[:,-3:], None)\n",
    "    dataloader = DataLoader(dataset, batch_size=40)\n",
    "\n",
    "    for idx, (a, b, c) in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            predict = model(a.to(DEVICE), b.to(DEVICE))[0]\n",
    "        last_predict.extend(predict.detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './saved_state_dict/L-BERT_epoch5_lr1e5_padembed_10Fold.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080e21fa79034b2fb5b5e8e8d97db501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3528.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#sd = torch.load('./saved_state_dict/epoch5lr2e5.pth')\n",
    "#model.load_state_dict(sd)\n",
    "model.eval()\n",
    "\n",
    "dataset = BonzDataset(new_data.iloc[:,-3:], None)\n",
    "dataloader = DataLoader(dataset, batch_size=40)\n",
    "\n",
    "last_predict = []\n",
    "for idx, (a, b, c) in enumerate(tqdm.notebook.tqdm(dataloader)):\n",
    "    with torch.no_grad():\n",
    "        predict = model(a.to(DEVICE), b.to(DEVICE))[0]\n",
    "    last_predict.extend(predict.detach().cpu().numpy().tolist())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_predict_ = torch.tensor(last_predict)\n",
    "last_predict_ = torch.softmax(last_predict_, 1)\n",
    "y_predict = torch.argmax(last_predict_, 1)\n",
    "y_true = np.asarray(list(new_data.labels))\n",
    "\n",
    "for i, asp in enumerate(ASPECT_NAMES):\n",
    "    print(f'{asp}:\\n{classification_report(y_true[:,i], y_predict[:,i])}')\n",
    "    \n",
    "    \n",
    "for i, asp in enumerate(ASPECT_NAMES):\n",
    "    print(f'{asp}:\\t{accuracy_score(y_true[:,i], y_predict[:,i]):.2f}\\t{f1_score(y_true[:,i], y_predict[:,i], average=\"macro\"):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Aspects</th>\n",
       "      <th>LEG</th>\n",
       "      <th>SIT</th>\n",
       "      <th>ENT</th>\n",
       "      <th>CUS</th>\n",
       "      <th>VOM</th>\n",
       "      <th>CLE</th>\n",
       "      <th>CKI</th>\n",
       "      <th>FNB</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "      <th>llr_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When I am planning a trip, first thing I do is...</td>\n",
       "      <td>5</td>\n",
       "      <td>['Legroom:5', 'Seat comfort:5', 'In-flight Ent...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2043, 1045, 2572, 4041, 1037, 4440, 1010...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[[3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recently flew to Tenerife with Jet2. The fligh...</td>\n",
       "      <td>4</td>\n",
       "      <td>['Legroom:4', 'Seat comfort:4', 'Customer serv...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 3728, 5520, 2000, 2702, 11124, 7959, 200...</td>\n",
       "      <td>[1, 1, 2, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once again easy airline to use especially if g...</td>\n",
       "      <td>5</td>\n",
       "      <td>['Legroom:4', 'Seat comfort:5', 'In-flight Ent...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2320, 2153, 3733, 8582, 2000, 2224, 2926...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[[3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A truly international airline. The crew repres...</td>\n",
       "      <td>4</td>\n",
       "      <td>['Legroom:4', 'Seat comfort:4', 'In-flight Ent...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[101, 1037, 5621, 2248, 8582, 1012, 1996, 3626...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 2, 2, 2]</td>\n",
       "      <td>[[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As always, they are efficient and clever. Boar...</td>\n",
       "      <td>5</td>\n",
       "      <td>['Legroom:3', 'Seat comfort:3', 'In-flight Ent...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2004, 2467, 1010, 2027, 2024, 8114, 1998...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 1, 0]</td>\n",
       "      <td>[[3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          ReviewText  Rating  \\\n",
       "0  When I am planning a trip, first thing I do is...       5   \n",
       "1  Recently flew to Tenerife with Jet2. The fligh...       4   \n",
       "2  Once again easy airline to use especially if g...       5   \n",
       "3  A truly international airline. The crew repres...       4   \n",
       "4  As always, they are efficient and clever. Boar...       5   \n",
       "\n",
       "                                             Aspects  LEG  SIT  ENT  CUS  VOM  \\\n",
       "0  ['Legroom:5', 'Seat comfort:5', 'In-flight Ent...    1    1    1    1    1   \n",
       "1  ['Legroom:4', 'Seat comfort:4', 'Customer serv...    1    1    2    1    1   \n",
       "2  ['Legroom:4', 'Seat comfort:5', 'In-flight Ent...    1    1    1    1    1   \n",
       "3  ['Legroom:4', 'Seat comfort:4', 'In-flight Ent...    1    1    1    1    0   \n",
       "4  ['Legroom:3', 'Seat comfort:3', 'In-flight Ent...    0    0    0    1    1   \n",
       "\n",
       "   CLE  CKI  FNB                                          input_ids  \\\n",
       "0    1    1    1  [101, 2043, 1045, 2572, 4041, 1037, 4440, 1010...   \n",
       "1    1    1    1  [101, 3728, 5520, 2000, 2702, 11124, 7959, 200...   \n",
       "2    1    1    1  [101, 2320, 2153, 3733, 8582, 2000, 2224, 2926...   \n",
       "3    2    2    2  [101, 1037, 5621, 2248, 8582, 1012, 1996, 3626...   \n",
       "4    1    1    0  [101, 2004, 2467, 1010, 2027, 2024, 8114, 1998...   \n",
       "\n",
       "                     labels                                     llr_embeddings  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1]  [[3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...  \n",
       "1  [1, 1, 2, 1, 1, 1, 1, 1]  [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1]  [[3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3,...  \n",
       "3  [1, 1, 1, 1, 0, 2, 2, 2]  [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3,...  \n",
       "4  [0, 0, 0, 1, 1, 1, 1, 0]  [[3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3,...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Aspects</th>\n",
       "      <th>LEG</th>\n",
       "      <th>SIT</th>\n",
       "      <th>ENT</th>\n",
       "      <th>CUS</th>\n",
       "      <th>VOM</th>\n",
       "      <th>CLE</th>\n",
       "      <th>CKI</th>\n",
       "      <th>FNB</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "      <th>llr_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So, I had this trip aligned for family leisure...</td>\n",
       "      <td>5</td>\n",
       "      <td>['Legroom:4', 'Seat comfort:5', 'In-flight Ent...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2061, 1010, 1045, 2018, 2023, 4440, 1311...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[[3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Refund agreed to months ago but basically been...</td>\n",
       "      <td>1</td>\n",
       "      <td>['Legroom:1', 'Seat comfort:1', 'In-flight Ent...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 25416, 8630, 3530, 2000, 2706, 3283, 202...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[[3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 0, 3, 3, 1, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flying to London on Singapore Airlines, we had...</td>\n",
       "      <td>4</td>\n",
       "      <td>['Legroom:3', 'Seat comfort:4', 'In-flight Ent...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 3909, 2000, 2414, 2006, 5264, 7608, 1010...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[[3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I thought we were making a safe choice booking...</td>\n",
       "      <td>1</td>\n",
       "      <td>['Customer service:1']</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[101, 1045, 2245, 2057, 2020, 2437, 1037, 3647...</td>\n",
       "      <td>[2, 2, 2, 0, 2, 2, 2, 2]</td>\n",
       "      <td>[[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wonderful service on our trip out to New Zeala...</td>\n",
       "      <td>4</td>\n",
       "      <td>['Legroom:5', 'Seat comfort:4', 'In-flight Ent...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 6919, 2326, 2006, 2256, 4440, 2041, 2000...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[[3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          ReviewText  Rating  \\\n",
       "0  So, I had this trip aligned for family leisure...       5   \n",
       "1  Refund agreed to months ago but basically been...       1   \n",
       "2  Flying to London on Singapore Airlines, we had...       4   \n",
       "3  I thought we were making a safe choice booking...       1   \n",
       "4  Wonderful service on our trip out to New Zeala...       4   \n",
       "\n",
       "                                             Aspects  LEG  SIT  ENT  CUS  VOM  \\\n",
       "0  ['Legroom:4', 'Seat comfort:5', 'In-flight Ent...    1    1    1    1    1   \n",
       "1  ['Legroom:1', 'Seat comfort:1', 'In-flight Ent...    0    0    0    0    0   \n",
       "2  ['Legroom:3', 'Seat comfort:4', 'In-flight Ent...    0    1    1    1    1   \n",
       "3                             ['Customer service:1']    2    2    2    0    2   \n",
       "4  ['Legroom:5', 'Seat comfort:4', 'In-flight Ent...    1    1    1    1    1   \n",
       "\n",
       "   CLE  CKI  FNB                                          input_ids  \\\n",
       "0    1    1    1  [101, 2061, 1010, 1045, 2018, 2023, 4440, 1311...   \n",
       "1    0    0    0  [101, 25416, 8630, 3530, 2000, 2706, 3283, 202...   \n",
       "2    1    1    1  [101, 3909, 2000, 2414, 2006, 5264, 7608, 1010...   \n",
       "3    2    2    2  [101, 1045, 2245, 2057, 2020, 2437, 1037, 3647...   \n",
       "4    1    1    1  [101, 6919, 2326, 2006, 2256, 4440, 2041, 2000...   \n",
       "\n",
       "                     labels                                     llr_embeddings  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1]  [[3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3,...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0]  [[3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 0, 3, 3, 1, 3,...  \n",
       "2  [0, 1, 1, 1, 1, 1, 1, 1]  [[3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3,...  \n",
       "3  [2, 2, 2, 0, 2, 2, 2, 2]  [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1]  [[3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
